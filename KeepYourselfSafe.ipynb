{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yeohz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\yeohz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yeohz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import re\n",
    "import demoji\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peek Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Ex Wife Threatening SuicideRecently I left my ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Am I weird I don't get affected by compliments...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Finally 2020 is almost over... So I can never ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>I‚Äôm so lostHello, my name is Adam (16) and I‚Äôv...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232069</th>\n",
       "      <td>348103</td>\n",
       "      <td>If you don't like rock then your not going to ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232070</th>\n",
       "      <td>348106</td>\n",
       "      <td>You how you can tell i have so many friends an...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232071</th>\n",
       "      <td>348107</td>\n",
       "      <td>pee probably tastes like salty teaüòèüí¶‚ÄºÔ∏è can som...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232072</th>\n",
       "      <td>348108</td>\n",
       "      <td>The usual stuff you find hereI'm not posting t...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232073</th>\n",
       "      <td>348110</td>\n",
       "      <td>I still haven't beaten the first boss in Hollo...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232074 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  \\\n",
       "0                2  Ex Wife Threatening SuicideRecently I left my ...   \n",
       "1                3  Am I weird I don't get affected by compliments...   \n",
       "2                4  Finally 2020 is almost over... So I can never ...   \n",
       "3                8          i need helpjust help me im crying so hard   \n",
       "4                9  I‚Äôm so lostHello, my name is Adam (16) and I‚Äôv...   \n",
       "...            ...                                                ...   \n",
       "232069      348103  If you don't like rock then your not going to ...   \n",
       "232070      348106  You how you can tell i have so many friends an...   \n",
       "232071      348107  pee probably tastes like salty teaüòèüí¶‚ÄºÔ∏è can som...   \n",
       "232072      348108  The usual stuff you find hereI'm not posting t...   \n",
       "232073      348110  I still haven't beaten the first boss in Hollo...   \n",
       "\n",
       "              class  \n",
       "0           suicide  \n",
       "1       non-suicide  \n",
       "2       non-suicide  \n",
       "3           suicide  \n",
       "4           suicide  \n",
       "...             ...  \n",
       "232069  non-suicide  \n",
       "232070  non-suicide  \n",
       "232071  non-suicide  \n",
       "232072      suicide  \n",
       "232073  non-suicide  \n",
       "\n",
       "[232074 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Dataset/Suicide_Detection.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "suicide        116037\n",
       "non-suicide    116037\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suicide and non-suicide text are equal in number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add space to some camel cased words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Ex Wife Threatening Suicide Recently I left my...\n",
       "1         Am I weird I don't get affected by compliments...\n",
       "2         Finally 2020 is almost over... So I can never ...\n",
       "3                 i need helpjust help me im crying so hard\n",
       "4         I‚Äôm so lost Hello, my name is Adam (16) and I‚Äô...\n",
       "                                ...                        \n",
       "232069    If you don't like rock then your not going to ...\n",
       "232070    You how you can tell i have so many friends an...\n",
       "232071    pee probably tastes like salty teaüòèüí¶‚ÄºÔ∏è can som...\n",
       "232072    The usual stuff you find here I'm not posting ...\n",
       "232073    I still haven't beaten the first boss in Hollo...\n",
       "Name: text, Length: 232074, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].replace(r\"(\\w)([A-Z])\", r\"\\1 \\2\", regex=True)\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Emojis into Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji_to_text(text):\n",
    "    return demoji.replace_with_desc(text, \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress Bar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 232074/232074 [22:55<00:00, 168.69it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"Progress Bar: \")\n",
    "df[\"text\"] = df[\"text\"].progress_apply(emoji_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Ex Wife Threatening Suicide Recently I left my...\n",
       "1         Am I weird I don't get affected by compliments...\n",
       "2         Finally 2020 is almost over... So I can never ...\n",
       "3                 i need helpjust help me im crying so hard\n",
       "4         I‚Äôm so lost Hello, my name is Adam (16) and I‚Äô...\n",
       "                                ...                        \n",
       "232069    If you don't like rock then your not going to ...\n",
       "232070    You how you can tell i have so many friends an...\n",
       "232071    pee probably tastes like salty tea smirking fa...\n",
       "232072    The usual stuff you find here I'm not posting ...\n",
       "232073    I still haven't beaten the first boss in Hollo...\n",
       "Name: text, Length: 232074, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowercase alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         ex wife threatening suicide recently i left my...\n",
       "1         am i weird i don't get affected by compliments...\n",
       "2         finally 2020 is almost over... so i can never ...\n",
       "3                 i need helpjust help me im crying so hard\n",
       "4         i‚Äôm so lost hello, my name is adam (16) and i‚Äô...\n",
       "                                ...                        \n",
       "232069    if you don't like rock then your not going to ...\n",
       "232070    you how you can tell i have so many friends an...\n",
       "232071    pee probably tastes like salty tea smirking fa...\n",
       "232072    the usual stuff you find here i'm not posting ...\n",
       "232073    i still haven't beaten the first boss in hollo...\n",
       "Name: text, Length: 232074, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yeohz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yeohz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Show incuded stop words\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordExceptions = [\"but\", \"if\", \"because\", \"against\",'no', 'nor','not', 'don', \"don't\", \"ain\", \n",
    "\"aren't\", 'aren',  'couldn',  \"couldn't\", 'didn', \"didn't\", \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven',\n",
    "\"haven't\", 'isn', \"isn't\", \"mustn't\", 'shan', \"shan't\", 'shouldn',\"shouldn't\", 'wasn', \"wasn't\",\n",
    "'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop word exceptions:  38\n",
      "Stop words:  179\n"
     ]
    }
   ],
   "source": [
    "print(\"Stop word exceptions: \", len(stopWordExceptions))\n",
    "print(\"Stop words: \", len(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customStopWords = [word for word in stopwords if word not in stopWordExceptions]\n",
    "len(customStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveStopWords(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_sentence = [word for word in word_tokens if word not in customStopWords]\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress Bar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 232074/232074 [04:12<00:00, 918.36it/s]\n"
     ]
    }
   ],
   "source": [
    "df[\"text\"] = df[\"text\"].progress_apply(RemoveStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [ex, wife, threatening, suicide, recently, lef...\n",
       "1         [weird, n't, get, affected, compliments, if, '...\n",
       "2         [finally, 2020, almost, ..., never, hear, ``, ...\n",
       "3                  [need, helpjust, help, im, crying, hard]\n",
       "4         [‚Äô, lost, hello, ,, name, adam, (, 16, ), ‚Äô, s...\n",
       "                                ...                        \n",
       "232069    [if, n't, like, rock, not, going, get, anythin...\n",
       "232070    [tell, many, friends, not, lonely, everything,...\n",
       "232071    [pee, probably, tastes, like, salty, tea, smir...\n",
       "232072    [usual, stuff, find, 'm, not, posting, sympath...\n",
       "232073    [still, n't, beaten, first, boss, hollow, knig...\n",
       "Name: text, Length: 232074, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemovePunctuations(text):\n",
    "    cleaned_text = []\n",
    "    for word in text:\n",
    "        word = re.sub('[^\\w\\s!?]','', word)\n",
    "        if word != \"\":\n",
    "            cleaned_text.append(word)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not alphabet o digit, remove\n",
    "df[\"text\"] = df['text'].apply(RemovePunctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [ex, wife, threatening, suicide, recently, lef...\n",
       "1         [weird, nt, get, affected, compliments, if, s,...\n",
       "2         [finally, 2020, almost, never, hear, 2020, bad...\n",
       "3                  [need, helpjust, help, im, crying, hard]\n",
       "4         [lost, hello, name, adam, 16, struggling, year...\n",
       "                                ...                        \n",
       "232069    [if, nt, like, rock, not, going, get, anything...\n",
       "232070    [tell, many, friends, not, lonely, everything,...\n",
       "232071    [pee, probably, tastes, like, salty, tea, smir...\n",
       "232072    [usual, stuff, find, m, not, posting, sympathy...\n",
       "232073    [still, nt, beaten, first, boss, hollow, knigh...\n",
       "Name: text, Length: 232074, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ex wife threatening suicide recently left wife...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weird nt get affected compliments if s coming ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finally 2020 almost never hear 2020 bad year e...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>need helpjust help im crying hard</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lost hello name adam 16 struggling years afrai...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232069</th>\n",
       "      <td>if nt like rock not going get anything but go ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232070</th>\n",
       "      <td>tell many friends not lonely everything depriv...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232071</th>\n",
       "      <td>pee probably tastes like salty tea smirking fa...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232072</th>\n",
       "      <td>usual stuff find m not posting sympathy pity b...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232073</th>\n",
       "      <td>still nt beaten first boss hollow knight ve fo...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232074 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text        class\n",
       "0       ex wife threatening suicide recently left wife...      suicide\n",
       "1       weird nt get affected compliments if s coming ...  non-suicide\n",
       "2       finally 2020 almost never hear 2020 bad year e...  non-suicide\n",
       "3                       need helpjust help im crying hard      suicide\n",
       "4       lost hello name adam 16 struggling years afrai...      suicide\n",
       "...                                                   ...          ...\n",
       "232069  if nt like rock not going get anything but go ...  non-suicide\n",
       "232070  tell many friends not lonely everything depriv...  non-suicide\n",
       "232071  pee probably tastes like salty tea smirking fa...  non-suicide\n",
       "232072  usual stuff find m not posting sympathy pity b...      suicide\n",
       "232073  still nt beaten first boss hollow knight ve fo...  non-suicide\n",
       "\n",
       "[232074 rows x 2 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = pd.read_csv(\"../Dataset/Suicide_Detection(After Remove Stop Words).csv\")\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nan values due to remove stop words; 18 records\n",
    "df_temp = df_temp.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ex wife threatening suicide recently left wife...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weird nt get affected compliments if s coming ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finally 2020 almost never hear 2020 bad year e...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>need helpjust help im crying hard</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lost hello name adam 16 struggling years afrai...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232069</th>\n",
       "      <td>if nt like rock not going get anything but go ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232070</th>\n",
       "      <td>tell many friends not lonely everything depriv...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232071</th>\n",
       "      <td>pee probably tastes like salty tea smirking fa...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232072</th>\n",
       "      <td>usual stuff find m not posting sympathy pity b...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232073</th>\n",
       "      <td>still nt beaten first boss hollow knight ve fo...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232056 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text        class\n",
       "0       ex wife threatening suicide recently left wife...      suicide\n",
       "1       weird nt get affected compliments if s coming ...  non-suicide\n",
       "2       finally 2020 almost never hear 2020 bad year e...  non-suicide\n",
       "3                       need helpjust help im crying hard      suicide\n",
       "4       lost hello name adam 16 struggling years afrai...      suicide\n",
       "...                                                   ...          ...\n",
       "232069  if nt like rock not going get anything but go ...  non-suicide\n",
       "232070  tell many friends not lonely everything depriv...  non-suicide\n",
       "232071  pee probably tastes like salty tea smirking fa...  non-suicide\n",
       "232072  usual stuff find m not posting sympathy pity b...      suicide\n",
       "232073  still nt beaten first boss hollow knight ve fo...  non-suicide\n",
       "\n",
       "[232056 rows x 2 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.to_csv(\"../Dataset/Suicide_Detection(After Remove Stop Words nan removed).csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_temp.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         ex wife threaten suicide recently leave wife g...\n",
      "1         weird nt get affect compliment if s come someo...\n",
      "2         finally 2020 almost never hear 2020 bad year e...\n",
      "3                            need helpjust help im cry hard\n",
      "4         lose hello name adam 16 struggle year afraid p...\n",
      "                                ...                        \n",
      "232069    if nt like rock not go get anything but go htt...\n",
      "232070    tell many friend not lonely everything deprive...\n",
      "232071    pee probably taste like salty tea smirk face s...\n",
      "232072    usual stuff find m not post sympathy pity beca...\n",
      "232073    still nt beat first bos hollow knight ve fough...\n",
      "Name: text, Length: 232056, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Initialize the WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# Function to map NLTK POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to noun\n",
    "\n",
    "\n",
    "# Function to lemmatize a text\n",
    "def lemmatize_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # POS tagging\n",
    "    tagged_words = nltk.pos_tag(tokens)\n",
    "    # Lemmatize each word with POS tag\n",
    "    lemmatized_words = [wnl.lemmatize(word, pos=get_wordnet_pos(tag)) for word, tag in tagged_words]\n",
    "    # Join lemmatized words into a single string\n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "    return lemmatized_text\n",
    "\n",
    "# # Ensure all entries in the 'text' column are strings\n",
    "# df[\"text\"] = df[\"text\"].apply(lambda x: ' '.join(x) if isinstance(x, list) else str(x))\n",
    "\n",
    "# Apply the lemmatization to the 'text' column\n",
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "\n",
    "# Print the DataFrame to see the results\n",
    "print(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Dataset/Suicide_Detection(After Lemmitization).csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     False\n",
       "class    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = pd.read_csv(\"../Dataset/Suicide_Detection(After Lemmitization).csv\")\n",
    "df_temp.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ex wife threaten suicide recently leave wife g...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weird nt get affect compliment if s come someo...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finally 2020 almost never hear 2020 bad year e...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>need helpjust help im cry hard</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lose hello name adam 16 struggle year afraid p...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232051</th>\n",
       "      <td>if nt like rock not go get anything but go htt...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232052</th>\n",
       "      <td>tell many friend not lonely everything deprive...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232053</th>\n",
       "      <td>pee probably taste like salty tea smirk face s...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232054</th>\n",
       "      <td>usual stuff find m not post sympathy pity beca...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232055</th>\n",
       "      <td>still nt beat first bos hollow knight ve fough...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232056 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text        class\n",
       "0       ex wife threaten suicide recently leave wife g...      suicide\n",
       "1       weird nt get affect compliment if s come someo...  non-suicide\n",
       "2       finally 2020 almost never hear 2020 bad year e...  non-suicide\n",
       "3                          need helpjust help im cry hard      suicide\n",
       "4       lose hello name adam 16 struggle year afraid p...      suicide\n",
       "...                                                   ...          ...\n",
       "232051  if nt like rock not go get anything but go htt...  non-suicide\n",
       "232052  tell many friend not lonely everything deprive...  non-suicide\n",
       "232053  pee probably taste like salty tea smirk face s...  non-suicide\n",
       "232054  usual stuff find m not post sympathy pity beca...      suicide\n",
       "232055  still nt beat first bos hollow knight ve fough...  non-suicide\n",
       "\n",
       "[232056 rows x 2 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_naive_bayes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "embeddings = model.encode(df['text'].tolist())\n",
    "\n",
    "df['embeddings'] = embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../Dataset/Suicide_Detection(After Embeddings).csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naive_bayes =  pd.read_csv(\"../Dataset/Suicide_Detection(After Lemmitization).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_naive_bayes[\"text\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ex wife threaten suicide recently leave wife good because cheat twice lie much decide refuse go back day ago begin threaten suicide tirelessly spent paat day talk keep hesitate because want believe ll come back know lot people threaten order get way but happen if really ? suppose handle death hand ? still love wife but not deal get cheat constantly feeling insecure m worry today may day hope much nt happen',\n",
       "       'weird nt get affect compliment if s come someone know irl but feel really good internet stranger',\n",
       "       'finally 2020 almost never hear 2020 bad year ever swear fuck god s annoy',\n",
       "       ...,\n",
       "       'pee probably taste like salty tea smirk face sweat droplet double exclamation mark someone drink pee confirm face roll eye double exclamation mark',\n",
       "       'usual stuff find m not post sympathy pity because know far bad situation mine but want get stuff but seem life no point everything do life ruin quit isolate everyone even family not even like tell family would help d consider psychotic probably right know m 18 no sense fuck universe want think seem like universe fuck make know s not m make fuck because nt think know want get people try help go rough patch get tough m do toughing life nt toughing look around family since m young ve see ridiculous shit happen s fuck post area because nt first time felt like try take life could nt w ha b ch k no w mean seriously cruel joke play despise life want know would like if end ca nt even s fuck because whenever around friend would put macho toughness guy like nothing hurt keep everything bottle nt anything life complain because option make good but good would come fail college because probably never get back track light socalled light end tunnel get small day',\n",
       "       'still nt beat first bos hollow knight ve fought time always die really early fight m terrible game yall'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_naive_bayes[\"text\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer (text/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Count:  3000\n"
     ]
    }
   ],
   "source": [
    "# Vectorize text based on count frequency\n",
    "vectorizer = CountVectorizer(max_features=3000)\n",
    " \n",
    "vectorizer.fit(df_naive_bayes[\"text\"].to_numpy())\n",
    "\n",
    "vectors = vectorizer.transform(df_naive_bayes[\"text\"].to_numpy())\n",
    "\n",
    "print(\"Vocabulary Count: \", len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232056, 3000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_array = vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Make sure records are not all 0\n",
    "for i in vectors.toarray()[5]:\n",
    "    if i == 1:\n",
    "        print(\"ok\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ex': 945,\n",
       " 'wife': 2924,\n",
       " 'threaten': 2681,\n",
       " 'suicide': 2576,\n",
       " 'recently': 2155,\n",
       " 'leave': 1519,\n",
       " 'good': 1166,\n",
       " 'because': 308,\n",
       " 'cheat': 479,\n",
       " 'twice': 2773,\n",
       " 'lie': 1541,\n",
       " 'much': 1738,\n",
       " 'decide': 703,\n",
       " 'refuse': 2170,\n",
       " 'go': 1158,\n",
       " 'back': 273,\n",
       " 'day': 688,\n",
       " 'ago': 132,\n",
       " 'begin': 315,\n",
       " 'spent': 2492,\n",
       " 'talk': 2616,\n",
       " 'keep': 1473,\n",
       " 'want': 2878,\n",
       " 'believe': 320,\n",
       " 'll': 1563,\n",
       " 'come': 542,\n",
       " 'know': 1492,\n",
       " 'lot': 1588,\n",
       " 'people': 1940,\n",
       " 'order': 1869,\n",
       " 'get': 1146,\n",
       " 'way': 2891,\n",
       " 'but': 427,\n",
       " 'happen': 1226,\n",
       " 'if': 1352,\n",
       " 'really': 2149,\n",
       " 'suppose': 2587,\n",
       " 'handle': 1224,\n",
       " 'death': 697,\n",
       " 'hand': 1222,\n",
       " 'still': 2527,\n",
       " 'love': 1591,\n",
       " 'not': 1809,\n",
       " 'deal': 694,\n",
       " 'constantly': 586,\n",
       " 'feeling': 1015,\n",
       " 'insecure': 1399,\n",
       " 'worry': 2952,\n",
       " 'today': 2707,\n",
       " 'may': 1641,\n",
       " 'hope': 1299,\n",
       " 'nt': 1818,\n",
       " 'weird': 2904,\n",
       " 'affect': 122,\n",
       " 'compliment': 558,\n",
       " 'someone': 2458,\n",
       " 'irl': 1436,\n",
       " 'feel': 1014,\n",
       " 'internet': 1423,\n",
       " 'stranger': 2538,\n",
       " 'finally': 1031,\n",
       " '2020': 33,\n",
       " 'almost': 149,\n",
       " 'never': 1782,\n",
       " 'hear': 1251,\n",
       " 'bad': 278,\n",
       " 'year': 2981,\n",
       " 'ever': 934,\n",
       " 'swear': 2600,\n",
       " 'fuck': 1111,\n",
       " 'god': 1161,\n",
       " 'annoy': 176,\n",
       " 'need': 1771,\n",
       " 'help': 1265,\n",
       " 'im': 1362,\n",
       " 'cry': 655,\n",
       " 'hard': 1233,\n",
       " 'lose': 1585,\n",
       " 'hello': 1264,\n",
       " 'name': 1752,\n",
       " '16': 21,\n",
       " 'struggle': 2551,\n",
       " 'afraid': 125,\n",
       " 'past': 1919,\n",
       " 'think': 2672,\n",
       " 'fear': 1009,\n",
       " 'anxiety': 182,\n",
       " 'close': 522,\n",
       " 'limit': 1551,\n",
       " 'quiet': 2110,\n",
       " 'long': 1579,\n",
       " 'scar': 2286,\n",
       " 'family': 993,\n",
       " 'aunt': 253,\n",
       " 'trigger': 2754,\n",
       " 'everyday': 937,\n",
       " 'hopeless': 1302,\n",
       " 'guilty': 1208,\n",
       " 'thing': 2671,\n",
       " 'do': 794,\n",
       " 'life': 1542,\n",
       " 'like': 1547,\n",
       " 'little': 1559,\n",
       " 'time': 2700,\n",
       " 'reveal': 2222,\n",
       " 'break': 391,\n",
       " 'saw': 2283,\n",
       " 'cut': 669,\n",
       " 'watch': 2888,\n",
       " 'something': 2459,\n",
       " 'average': 260,\n",
       " 'make': 1612,\n",
       " 'absolutely': 78,\n",
       " 'later': 1505,\n",
       " 'find': 1035,\n",
       " 'attempt': 245,\n",
       " 'overdose': 1883,\n",
       " 'pill': 1969,\n",
       " 'hang': 1225,\n",
       " 'noose': 1802,\n",
       " 'first': 1040,\n",
       " 'therapy': 2663,\n",
       " 'diagnose': 746,\n",
       " 'severe': 2344,\n",
       " 'depression': 722,\n",
       " 'social': 2447,\n",
       " 'eat': 857,\n",
       " 'disorder': 785,\n",
       " 'transfer': 2740,\n",
       " 'group': 1199,\n",
       " 'reason': 2150,\n",
       " 'anxious': 183,\n",
       " 'eventually': 933,\n",
       " 'last': 1502,\n",
       " 'session': 2339,\n",
       " 'show': 2382,\n",
       " 'result': 2217,\n",
       " 'daily': 676,\n",
       " 'check': 480,\n",
       " 'step': 2524,\n",
       " 'survey': 2594,\n",
       " 'put': 2102,\n",
       " 'horrible': 1307,\n",
       " 'mom': 1716,\n",
       " 'amazing': 161,\n",
       " 'happy': 1231,\n",
       " 'see': 2315,\n",
       " 'anti': 180,\n",
       " 'sorry': 2471,\n",
       " 'forget': 1072,\n",
       " 'finish': 1038,\n",
       " 'prescription': 2040,\n",
       " 'nor': 1804,\n",
       " 'right': 2230,\n",
       " 'type': 2778,\n",
       " 'drug': 832,\n",
       " 'take': 2613,\n",
       " 'recommend': 2157,\n",
       " 'schedule': 2292,\n",
       " 'week': 2900,\n",
       " 'stop': 2532,\n",
       " 'damage': 677,\n",
       " 'cause': 456,\n",
       " 'even': 931,\n",
       " 'everything': 939,\n",
       " 'relapse': 2178,\n",
       " 'develop': 743,\n",
       " 'insomnia': 1404,\n",
       " 'worthless': 2957,\n",
       " 'question': 2107,\n",
       " 'motivation': 1732,\n",
       " 'move': 1735,\n",
       " 'bed': 310,\n",
       " 'ask': 230,\n",
       " 'nearly': 1767,\n",
       " 'every': 935,\n",
       " 'night': 1790,\n",
       " 'everytime': 940,\n",
       " 'please': 1992,\n",
       " 'anyone': 187,\n",
       " 'might': 1684,\n",
       " 'shape': 2356,\n",
       " 'idk': 1350,\n",
       " 'anymore': 185,\n",
       " 'dont': 801,\n",
       " 'nothing': 1811,\n",
       " 'nowhere': 1816,\n",
       " 'either': 874,\n",
       " 'sad': 2271,\n",
       " 'ignore': 1355,\n",
       " 'friend': 1101,\n",
       " 'loose': 1583,\n",
       " 'girlfriend': 1154,\n",
       " 'hurt': 1335,\n",
       " 'everyone': 938,\n",
       " 'anything': 188,\n",
       " 'behind': 318,\n",
       " 'education': 863,\n",
       " 'alone': 150,\n",
       " 'ive': 1449,\n",
       " 'enjoy': 902,\n",
       " 'no': 1796,\n",
       " 'dream': 822,\n",
       " 'care': 447,\n",
       " 'friends': 1103,\n",
       " 'complicate': 557,\n",
       " 'word': 2947,\n",
       " 'describe': 724,\n",
       " 'would': 2959,\n",
       " 'end': 894,\n",
       " 'strong': 2549,\n",
       " 'brave': 388,\n",
       " 'enough': 905,\n",
       " 'weak': 2892,\n",
       " 'push': 2100,\n",
       " 'away': 265,\n",
       " 'emotion': 884,\n",
       " 'empty': 890,\n",
       " 'use': 2824,\n",
       " 'normal': 1805,\n",
       " 'understand': 2796,\n",
       " 'hop': 1298,\n",
       " 'mention': 1672,\n",
       " 'die': 751,\n",
       " 'bring': 400,\n",
       " 'realise': 2145,\n",
       " 'cant': 443,\n",
       " 'mean': 1645,\n",
       " 'ramble': 2122,\n",
       " 'probably': 2060,\n",
       " 'regret': 2173,\n",
       " 'post': 2020,\n",
       " 'ill': 1359,\n",
       " 'place': 1978,\n",
       " 'gun': 1210,\n",
       " 'head': 1246,\n",
       " 'instead': 1408,\n",
       " 'plus': 1996,\n",
       " 'meaningless': 1648,\n",
       " 'future': 1125,\n",
       " 'bleak': 355,\n",
       " 'could': 613,\n",
       " 'cure': 663,\n",
       " 'cancer': 442,\n",
       " 'useful': 2826,\n",
       " 'warn': 2883,\n",
       " 'excuse': 953,\n",
       " 'self': 2319,\n",
       " 'burn': 421,\n",
       " 'crisis': 649,\n",
       " 'line': 1552,\n",
       " 'panic': 1901,\n",
       " 'attack': 244,\n",
       " 'healthy': 1250,\n",
       " 'stupid': 2556,\n",
       " 'impulse': 1374,\n",
       " 'ea': 846,\n",
       " 'father': 1004,\n",
       " 'daughter': 687,\n",
       " 'history': 1280,\n",
       " 'together': 2709,\n",
       " '12': 17,\n",
       " 'always': 159,\n",
       " 'wrist': 2966,\n",
       " 'easier': 854,\n",
       " 'one': 1854,\n",
       " 'work': 2948,\n",
       " 'car': 445,\n",
       " 'harm': 1236,\n",
       " 'without': 2937,\n",
       " 'usual': 2830,\n",
       " 'moment': 1717,\n",
       " 'say': 2284,\n",
       " 'touch': 2727,\n",
       " 'hot': 1313,\n",
       " 'pattern': 1923,\n",
       " 'side': 2390,\n",
       " 'inch': 1377,\n",
       " 'kind': 1481,\n",
       " 'deep': 706,\n",
       " 'explain': 966,\n",
       " 'maybe': 1642,\n",
       " 'fix': 1045,\n",
       " 'able': 74,\n",
       " 'quit': 2111,\n",
       " 'edgy': 861,\n",
       " 'conscious': 578,\n",
       " 'stand': 2511,\n",
       " 'draw': 820,\n",
       " 'yes': 2984,\n",
       " 'play': 1987,\n",
       " 'guitar': 1209,\n",
       " 'honestly': 1295,\n",
       " 'stick': 2526,\n",
       " 'taste': 2622,\n",
       " 'music': 1743,\n",
       " 'rock': 2244,\n",
       " 'alt': 156,\n",
       " 'metal': 1676,\n",
       " '90': 65,\n",
       " 'unique': 2806,\n",
       " 'style': 2557,\n",
       " 'classmate': 511,\n",
       " 'rap': 2128,\n",
       " 'dm': 793,\n",
       " 'fit': 1043,\n",
       " 'others': 1874,\n",
       " 'copy': 603,\n",
       " 'another': 178,\n",
       " 'kid': 1478,\n",
       " 'phase': 1956,\n",
       " 'many': 1622,\n",
       " 'look': 1581,\n",
       " 'kinda': 1482,\n",
       " 'agree': 134,\n",
       " 'continue': 592,\n",
       " 'ca': 432,\n",
       " 'wear': 2893,\n",
       " 'cross': 650,\n",
       " 'chain': 468,\n",
       " 'confuse': 574,\n",
       " 'lo': 1565,\n",
       " 'ut': 2832,\n",
       " 'ha': 1215,\n",
       " 'se': 2305,\n",
       " 'tiktok': 2697,\n",
       " 'boy': 383,\n",
       " 'goddamn': 1162,\n",
       " 'hate': 1240,\n",
       " '20': 26,\n",
       " 'old': 1851,\n",
       " 'male': 1615,\n",
       " 'trash': 2744,\n",
       " 'matter': 1638,\n",
       " 'ug': 2781,\n",
       " 'bipolar': 339,\n",
       " 'cripple': 648,\n",
       " 'top': 2721,\n",
       " 'hat': 1239,\n",
       " '247': 39,\n",
       " 'room': 2249,\n",
       " 'thinking': 2673,\n",
       " 'pop': 2012,\n",
       " 'xanax': 2973,\n",
       " 'try': 2764,\n",
       " 'numb': 1820,\n",
       " 'pain': 1894,\n",
       " 'bit': 344,\n",
       " 'crash': 634,\n",
       " 'don': 799,\n",
       " 'communicate': 548,\n",
       " 'relationship': 2180,\n",
       " 'popular': 2013,\n",
       " 'dad': 674,\n",
       " 'pas': 1915,\n",
       " 'dark': 683,\n",
       " 'hole': 1286,\n",
       " 'arrest': 220,\n",
       " 'numerous': 1822,\n",
       " 'mental': 1670,\n",
       " 'hospital': 1311,\n",
       " 'haven': 1243,\n",
       " 'kill': 1479,\n",
       " 'yet': 2986,\n",
       " 'brother': 405,\n",
       " 'didn': 749,\n",
       " 'dead': 692,\n",
       " 'point': 2003,\n",
       " 'support': 2585,\n",
       " 'isn': 1439,\n",
       " 'alive': 147,\n",
       " 'guy': 1212,\n",
       " 'child': 487,\n",
       " 'choose': 494,\n",
       " 'rest': 2215,\n",
       " 'sleep': 2423,\n",
       " 'painkiller': 1896,\n",
       " 'wait': 2873,\n",
       " 'imagine': 1364,\n",
       " 'weight': 2903,\n",
       " 'gain': 1127,\n",
       " 'hair': 1218,\n",
       " 'loss': 1587,\n",
       " 'mess': 1673,\n",
       " 'teeth': 2638,\n",
       " 'bone': 370,\n",
       " 'health': 1249,\n",
       " 'issue': 1444,\n",
       " 'hormone': 1304,\n",
       " 'new': 1783,\n",
       " 'generation': 1142,\n",
       " 'amp': 168,\n",
       " 'world': 2950,\n",
       " 'progress': 2072,\n",
       " 'useless': 2827,\n",
       " 'angry': 172,\n",
       " 'piece': 1967,\n",
       " 'shit': 2367,\n",
       " 'totally': 2726,\n",
       " 'secretly': 2312,\n",
       " 'already': 153,\n",
       " 'avoid': 261,\n",
       " 'hit': 1281,\n",
       " 'train': 2737,\n",
       " 'painful': 1895,\n",
       " 'country': 620,\n",
       " 'suffer': 2569,\n",
       " 'though': 2676,\n",
       " 'painless': 1897,\n",
       " 'method': 1677,\n",
       " 'interesting': 1421,\n",
       " 'information': 1393,\n",
       " 'bunch': 419,\n",
       " 'spit': 2496,\n",
       " 'personal': 1950,\n",
       " 'obviously': 1830,\n",
       " 'least': 1518,\n",
       " 'troll': 2756,\n",
       " 'laugh': 1506,\n",
       " 'desire': 729,\n",
       " 'grow': 1200,\n",
       " 'left': 1522,\n",
       " 'main': 1607,\n",
       " 'goal': 1159,\n",
       " 'throughout': 2684,\n",
       " 'process': 2063,\n",
       " 'certainly': 466,\n",
       " 'nice': 1789,\n",
       " 'forum': 1082,\n",
       " 'privacy': 2056,\n",
       " 'ridiculous': 2229,\n",
       " 'expectation': 961,\n",
       " 'consider': 582,\n",
       " 'source': 2476,\n",
       " 'suicidal': 2575,\n",
       " 'edit': 862,\n",
       " 'smart': 2434,\n",
       " 'app': 199,\n",
       " 'porn': 2014,\n",
       " 'wtf': 2969,\n",
       " 'seem': 2317,\n",
       " 'young': 2989,\n",
       " 'transgender': 2741,\n",
       " 'sure': 2588,\n",
       " 'tell': 2639,\n",
       " 'actually': 106,\n",
       " 'trans': 2739,\n",
       " 'overwhelm': 1886,\n",
       " 'wish': 2934,\n",
       " 'religious': 2188,\n",
       " 'accept': 86,\n",
       " 'yesterday': 2985,\n",
       " 'barely': 289,\n",
       " 'blood': 360,\n",
       " 'correctly': 609,\n",
       " 'pursue': 2099,\n",
       " 'money': 1719,\n",
       " 'field': 1023,\n",
       " 'unless': 2812,\n",
       " 'become': 309,\n",
       " 'famous': 994,\n",
       " 'currently': 666,\n",
       " 'seriously': 2335,\n",
       " 'debate': 698,\n",
       " 'longer': 1580,\n",
       " 'bear': 304,\n",
       " 'girl': 1153,\n",
       " 'well': 2906,\n",
       " 'screw': 2302,\n",
       " 'lock': 1571,\n",
       " 'school': 2295,\n",
       " 'toilet': 2710,\n",
       " 'live': 1560,\n",
       " 'story': 2535,\n",
       " 'assignment': 236,\n",
       " 'due': 837,\n",
       " 'tomorrow': 2715,\n",
       " 'start': 2515,\n",
       " 'knife': 1490,\n",
       " 'give': 1155,\n",
       " 'free': 1092,\n",
       " 'fun': 1120,\n",
       " 'depress': 720,\n",
       " 'sister': 2408,\n",
       " 'realize': 2148,\n",
       " 'haha': 1217,\n",
       " 'goodbye': 1167,\n",
       " 'disability': 766,\n",
       " 'sick': 2389,\n",
       " 'living': 1562,\n",
       " 'tire': 2703,\n",
       " 'single': 2406,\n",
       " 'reject': 2176,\n",
       " 'monster': 1722,\n",
       " 'connect': 576,\n",
       " 'loneliness': 1577,\n",
       " 'swallow': 2599,\n",
       " 'inside': 1401,\n",
       " 'consume': 587,\n",
       " 'darkness': 684,\n",
       " 'everywhere': 941,\n",
       " 'towards': 2730,\n",
       " 'remind': 2192,\n",
       " 'read': 2141,\n",
       " 'toxic': 2732,\n",
       " 'house': 1318,\n",
       " 'best': 326,\n",
       " 'cope': 602,\n",
       " 'etc': 926,\n",
       " 'stay': 2521,\n",
       " 'home': 1290,\n",
       " 'trap': 2743,\n",
       " 'void': 2866,\n",
       " 'dear': 696,\n",
       " 'whoever': 2919,\n",
       " 'doubt': 807,\n",
       " 'fall': 990,\n",
       " 'task': 2621,\n",
       " 'forward': 1083,\n",
       " 'whatsoever': 2912,\n",
       " 'save': 2282,\n",
       " 'felt': 1018,\n",
       " 'sound': 2475,\n",
       " 'worth': 2956,\n",
       " 'okay': 1849,\n",
       " 'open': 1860,\n",
       " 'completely': 555,\n",
       " 'ease': 853,\n",
       " 'else': 878,\n",
       " 'share': 2357,\n",
       " 'dare': 682,\n",
       " 'crazy': 637,\n",
       " 'scenario': 2290,\n",
       " 'apart': 194,\n",
       " 'except': 950,\n",
       " 'problem': 2061,\n",
       " 'face': 978,\n",
       " 'relate': 2179,\n",
       " 'breakup': 394,\n",
       " 'whenever': 2914,\n",
       " 'star': 2513,\n",
       " 'sky': 2419,\n",
       " 'none': 1800,\n",
       " 'slowly': 2432,\n",
       " 'drift': 824,\n",
       " 'exactly': 947,\n",
       " 'involve': 1432,\n",
       " 'blame': 352,\n",
       " 'tendency': 2644,\n",
       " 'thought': 2677,\n",
       " 'wasn': 2885,\n",
       " 'interaction': 1418,\n",
       " 'fair': 986,\n",
       " 'around': 219,\n",
       " 'extremely': 976,\n",
       " 'spend': 2490,\n",
       " 'four': 1086,\n",
       " 'month': 1723,\n",
       " 'legitimately': 1527,\n",
       " 'thanks': 2658,\n",
       " 'stress': 2543,\n",
       " 'far': 998,\n",
       " 'various': 2844,\n",
       " 'beyond': 330,\n",
       " 'control': 595,\n",
       " 'hold': 1285,\n",
       " 'incredibly': 1385,\n",
       " 'detail': 739,\n",
       " 'person': 1949,\n",
       " 'genuinely': 1144,\n",
       " 'concern': 562,\n",
       " 'tried': 2753,\n",
       " 'attractive': 250,\n",
       " 'ten': 2642,\n",
       " 'prior': 2054,\n",
       " 'picture': 1966,\n",
       " 'send': 2325,\n",
       " 'snapchat': 2442,\n",
       " 'miss': 1702,\n",
       " 'return': 2221,\n",
       " 'extreme': 975,\n",
       " 'fine': 1036,\n",
       " 'sometimes': 2461,\n",
       " 'case': 451,\n",
       " 'morning': 1727,\n",
       " 'significant': 2393,\n",
       " 'also': 155,\n",
       " 'drive': 827,\n",
       " 'two': 2777,\n",
       " 'lay': 1509,\n",
       " 'ceiling': 461,\n",
       " 'tear': 2631,\n",
       " 'wrong': 2968,\n",
       " 'outside': 1879,\n",
       " 'view': 2856,\n",
       " 'complete': 554,\n",
       " 'luck': 1596,\n",
       " 'idea': 1344,\n",
       " 'online': 1855,\n",
       " 'facebook': 979,\n",
       " 'absolute': 77,\n",
       " 'low': 1594,\n",
       " 'message': 1674,\n",
       " 'prepare': 2038,\n",
       " 'wonderful': 2944,\n",
       " 'conversation': 596,\n",
       " 'childhood': 488,\n",
       " 'remember': 2191,\n",
       " 'subject': 2559,\n",
       " 'change': 472,\n",
       " 'upset': 2820,\n",
       " 'couldn': 614,\n",
       " 'especially': 921,\n",
       " 'decade': 700,\n",
       " 'joke': 1461,\n",
       " 'red': 2162,\n",
       " 'string': 2548,\n",
       " 'fate': 1003,\n",
       " 'dumb': 839,\n",
       " 'fact': 981,\n",
       " 'socially': 2449,\n",
       " 'awkward': 269,\n",
       " 'freeze': 1094,\n",
       " 'bore': 373,\n",
       " 'talked': 2617,\n",
       " 'actual': 105,\n",
       " 'friendship': 1104,\n",
       " 'fight': 1024,\n",
       " 'game': 1129,\n",
       " 'boyfriend': 384,\n",
       " 'bottom': 380,\n",
       " 'fault': 1005,\n",
       " 'true': 2759,\n",
       " 'badly': 279,\n",
       " 'suffocate': 2571,\n",
       " 'bother': 378,\n",
       " 'space': 2478,\n",
       " 'depressed': 721,\n",
       " 'weekend': 2901,\n",
       " 'cancel': 441,\n",
       " 'plan': 1981,\n",
       " 'sink': 2407,\n",
       " 'mainly': 1608,\n",
       " 'awake': 262,\n",
       " 'offer': 1840,\n",
       " 'must': 1744,\n",
       " 'exhaust': 955,\n",
       " 'tired': 2704,\n",
       " 'write': 2967,\n",
       " 'recognize': 2156,\n",
       " 'flaw': 1051,\n",
       " 'knowledge': 1493,\n",
       " 'entire': 908,\n",
       " 'zero': 2995,\n",
       " 'notice': 1813,\n",
       " 'fell': 1016,\n",
       " 'earth': 852,\n",
       " 'fade': 983,\n",
       " 'speak': 2482,\n",
       " 'ne': 1764,\n",
       " 'water': 2889,\n",
       " 'smell': 2436,\n",
       " 'air': 139,\n",
       " 'great': 1189,\n",
       " 'ring': 2231,\n",
       " 'three': 2682,\n",
       " 'wise': 2933,\n",
       " 'be': 301,\n",
       " 'seven': 2342,\n",
       " 'mountain': 1733,\n",
       " 'nine': 1792,\n",
       " 'gift': 1152,\n",
       " 'race': 2116,\n",
       " 'men': 1669,\n",
       " 'power': 2029,\n",
       " 'within': 2936,\n",
       " 'strength': 2542,\n",
       " 'land': 1498,\n",
       " 'fire': 1039,\n",
       " 'doom': 802,\n",
       " 'lord': 1584,\n",
       " 'master': 1632,\n",
       " 'pour': 2026,\n",
       " 'rule': 2264,\n",
       " 'march': 1623,\n",
       " 'against': 129,\n",
       " 'army': 218,\n",
       " 'fought': 1085,\n",
       " 'freedom': 1093,\n",
       " 'near': 1765,\n",
       " 'son': 2464,\n",
       " 'king': 1484,\n",
       " 'enemy': 897,\n",
       " 'defeat': 708,\n",
       " 'chance': 471,\n",
       " 'destroy': 737,\n",
       " 'evil': 943,\n",
       " 'forever': 1071,\n",
       " 'heart': 1254,\n",
       " 'easily': 855,\n",
       " 'betray': 328,\n",
       " 'half': 1219,\n",
       " 'thousand': 2678,\n",
       " 'creature': 641,\n",
       " 'tunnel': 2769,\n",
       " 'five': 1044,\n",
       " 'hundred': 1332,\n",
       " 'poison': 2005,\n",
       " 'mind': 1691,\n",
       " 'creep': 643,\n",
       " 'forest': 1070,\n",
       " 'shadow': 2352,\n",
       " 'abandon': 72,\n",
       " 'intend': 1414,\n",
       " 'pick': 1965,\n",
       " 'soon': 2466,\n",
       " 'heavy': 1260,\n",
       " 'wake': 2874,\n",
       " 'benefit': 323,\n",
       " 'accord': 91,\n",
       " 'prevent': 2048,\n",
       " 'flash': 1048,\n",
       " 'woman': 2941,\n",
       " 'helpful': 1266,\n",
       " 'cool': 600,\n",
       " 'core': 604,\n",
       " 'body': 367,\n",
       " 'improve': 1372,\n",
       " 'crack': 631,\n",
       " 'dry': 834,\n",
       " 'increase': 1382,\n",
       " 'potential': 2023,\n",
       " 'bc': 300,\n",
       " 'http': 1323,\n",
       " 'accidentally': 89,\n",
       " 'discover': 776,\n",
       " 'ability': 73,\n",
       " 'achieve': 95,\n",
       " '30': 46,\n",
       " 'disease': 780,\n",
       " 'area': 212,\n",
       " 'skin': 2415,\n",
       " 'usually': 2831,\n",
       " 'toe': 2708,\n",
       " 'finger': 1037,\n",
       " 'foot': 1067,\n",
       " 'warm': 2882,\n",
       " 'reddit': 2163,\n",
       " 'user': 2828,\n",
       " 'subreddit': 2561,\n",
       " 'often': 1844,\n",
       " 'tonight': 2719,\n",
       " 'active': 102,\n",
       " 'redditor': 2164,\n",
       " 'literally': 1558,\n",
       " 'series': 2333,\n",
       " 'diet': 753,\n",
       " 'hollow': 1288,\n",
       " 'extend': 972,\n",
       " 'text': 2650,\n",
       " 'hour': 1317,\n",
       " 'pretty': 2047,\n",
       " 'interested': 1420,\n",
       " 'overwhelming': 1887,\n",
       " 'late': 1503,\n",
       " 'miserable': 1700,\n",
       " 'mine': 1693,\n",
       " 'certain': 465,\n",
       " 'call': 435,\n",
       " 'chest': 485,\n",
       " 'waste': 2887,\n",
       " 'x200': 2972,\n",
       " 'lol': 1576,\n",
       " 'normally': 1806,\n",
       " 'cringe': 647,\n",
       " 'loathe': 1568,\n",
       " 'muster': 1745,\n",
       " 'courage': 622,\n",
       " 'follow': 1063,\n",
       " 'worst': 2955,\n",
       " 'appreciate': 208,\n",
       " 'community': 550,\n",
       " 'let': 1533,\n",
       " 'song': 2465,\n",
       " 'lt': 1595,\n",
       " 'vibe': 2852,\n",
       " 'ur': 2822,\n",
       " 'slow': 2431,\n",
       " 'listen': 1556,\n",
       " 'effective': 866,\n",
       " 'man': 1616,\n",
       " 'drunk': 833,\n",
       " 'easy': 856,\n",
       " 'sweet': 2602,\n",
       " 'arm': 217,\n",
       " 'next': 1785,\n",
       " 'coward': 628,\n",
       " 'soul': 2474,\n",
       " 'bullshit': 417,\n",
       " 'award': 263,\n",
       " 'expensive': 963,\n",
       " 'drown': 831,\n",
       " 'state': 2517,\n",
       " 'university': 2810,\n",
       " 'drop': 829,\n",
       " 'financial': 1033,\n",
       " 'since': 2403,\n",
       " 'anywhere': 192,\n",
       " 'job': 1459,\n",
       " '15': 20,\n",
       " 'food': 1065,\n",
       " 'stuck': 2552,\n",
       " 'part': 1909,\n",
       " 'apply': 206,\n",
       " 'explanation': 967,\n",
       " 'afford': 124,\n",
       " 'gross': 1197,\n",
       " 'bank': 286,\n",
       " 'account': 92,\n",
       " 'clue': 529,\n",
       " 'pay': 1925,\n",
       " 'rent': 2196,\n",
       " 'trouble': 2757,\n",
       " 'crush': 654,\n",
       " 're': 2137,\n",
       " 'lonely': 1578,\n",
       " '22': 36,\n",
       " 'loser': 1586,\n",
       " 'fat': 1002,\n",
       " 'pound': 2025,\n",
       " 'small': 2433,\n",
       " 'penis': 1938,\n",
       " 'gf': 1147,\n",
       " 'experience': 964,\n",
       " 'ugly': 2783,\n",
       " 'size': 2413,\n",
       " 'real': 2144,\n",
       " 'college': 538,\n",
       " 'career': 448,\n",
       " 'minimum': 1695,\n",
       " 'wage': 2872,\n",
       " 'paycheck': 1926,\n",
       " 'big': 333,\n",
       " 'successful': 2565,\n",
       " 'ungrateful': 2802,\n",
       " 'vent': 2847,\n",
       " 'chat': 477,\n",
       " 'sometime': 2460,\n",
       " 'lung': 1600,\n",
       " 'fucking': 1115,\n",
       " 'apologize': 197,\n",
       " '100': 13,\n",
       " 'sent': 2329,\n",
       " 'video': 2854,\n",
       " 'eye': 977,\n",
       " 'forgive': 1073,\n",
       " 'guess': 1205,\n",
       " 'isolate': 1441,\n",
       " 'reach': 2138,\n",
       " 'jump': 1467,\n",
       " 'roof': 2248,\n",
       " 'serious': 2334,\n",
       " 'wont': 2945,\n",
       " 'thats': 2659,\n",
       " 'sit': 2409,\n",
       " 'dose': 805,\n",
       " 'medication': 1657,\n",
       " 'second': 2310,\n",
       " 'hey': 1270,\n",
       " 'gon': 1165,\n",
       " 'na': 1748,\n",
       " 'skill': 2414,\n",
       " 'light': 1546,\n",
       " 'cock': 531,\n",
       " 'minute': 1697,\n",
       " 'quite': 2112,\n",
       " 'genuine': 1143,\n",
       " 'strange': 2537,\n",
       " 'truly': 2760,\n",
       " 'suddenly': 2568,\n",
       " 'hardly': 1235,\n",
       " 'enter': 906,\n",
       " 'med': 1654,\n",
       " 'business': 425,\n",
       " 'huge': 1326,\n",
       " 'mistake': 1703,\n",
       " 'along': 151,\n",
       " 'figure': 1025,\n",
       " 'credit': 642,\n",
       " 'bill': 335,\n",
       " 'bos': 376,\n",
       " 'crap': 632,\n",
       " 'manager': 1618,\n",
       " 'switch': 2605,\n",
       " 'unlike': 2813,\n",
       " 'decision': 704,\n",
       " 'present': 2042,\n",
       " 'button': 429,\n",
       " '24': 38,\n",
       " 'hr': 1321,\n",
       " 'thankful': 2656,\n",
       " 'email': 880,\n",
       " 'function': 1121,\n",
       " 'yall': 2977,\n",
       " 'book': 371,\n",
       " 'guilt': 1207,\n",
       " 'trip': 2755,\n",
       " 'situation': 2411,\n",
       " 'deserve': 726,\n",
       " 'whatever': 2910,\n",
       " 'math': 1637,\n",
       " 'class': 510,\n",
       " 'horny': 1306,\n",
       " 'zone': 2998,\n",
       " 'partner': 1913,\n",
       " 'damn': 678,\n",
       " 'spoil': 2498,\n",
       " 'ta': 2611,\n",
       " 've': 2845,\n",
       " 'nobody': 1797,\n",
       " 'suck': 2566,\n",
       " 'impossible': 1371,\n",
       " 'ri': 2225,\n",
       " 'ng': 1786,\n",
       " 'sa': 2268,\n",
       " 'bl': 348,\n",
       " 'ch': 467,\n",
       " 'oo': 1857,\n",
       " 'iv': 1448,\n",
       " 'es': 919,\n",
       " 'da': 673,\n",
       " 'ry': 2267,\n",
       " 'po': 1999,\n",
       " 'li': 1538,\n",
       " 'oi': 1846,\n",
       " 'el': 875,\n",
       " 'ic': 1340,\n",
       " 'ay': 270,\n",
       " 'et': 925,\n",
       " 'ee': 864,\n",
       " 'financially': 1034,\n",
       " 'responsible': 2214,\n",
       " 'flat': 1050,\n",
       " 'cost': 610,\n",
       " 'clean': 513,\n",
       " 'wonder': 2943,\n",
       " 'celebrate': 462,\n",
       " 'valentine': 2840,\n",
       " 'less': 1531,\n",
       " 'supportive': 2586,\n",
       " 'thank': 2655,\n",
       " 'kindness': 1483,\n",
       " 'degree': 711,\n",
       " 'repeat': 2198,\n",
       " 'link': 1553,\n",
       " 'serve': 2336,\n",
       " 'reference': 2168,\n",
       " 'insane': 1398,\n",
       " 'event': 932,\n",
       " 'rant': 2127,\n",
       " 'reading': 2142,\n",
       " 'intense': 1415,\n",
       " 'existence': 957,\n",
       " 'force': 1069,\n",
       " 'reply': 2201,\n",
       " 'comment': 545,\n",
       " 'energy': 898,\n",
       " 'advance': 116,\n",
       " 'circumstance': 505,\n",
       " 'mood': 1724,\n",
       " 'cheer': 481,\n",
       " 'happiness': 1230,\n",
       " 'therapist': 2662,\n",
       " 'fake': 989,\n",
       " 'full': 1118,\n",
       " 'disconnect': 774,\n",
       " 'meant': 1649,\n",
       " 'clear': 514,\n",
       " 'buy': 430,\n",
       " 'mask': 1629,\n",
       " 'doctor': 795,\n",
       " 'opinion': 1862,\n",
       " 'dick': 748,\n",
       " 'christmas': 499,\n",
       " 'drink': 825,\n",
       " 'age': 130,\n",
       " 'hung': 1333,\n",
       " 'alcoholic': 145,\n",
       " 'drinking': 826,\n",
       " 'rape': 2129,\n",
       " 'excite': 952,\n",
       " 'reaction': 2140,\n",
       " 'bullet': 416,\n",
       " 'hell': 1263,\n",
       " 'pistol': 1973,\n",
       " 'rough': 2254,\n",
       " 'weary': 2894,\n",
       " 'basically': 293,\n",
       " 'direction': 762,\n",
       " 'object': 1827,\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoder (class/y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode sentiment labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labels = df_naive_bayes[\"class\"].values\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 1 0]\n",
      "No. of Records:  232056\n"
     ]
    }
   ],
   "source": [
    "print(encoded_labels)\n",
    "print(\"No. of Records: \", len(encoded_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into Train, Val, Test: 70%, 15%, 15%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (162439, 3000)\n",
      "x_remain shape:  (69617, 3000)\n",
      "y_train shape:  (162439,)\n",
      "y_remain shape:  (69617,)\n"
     ]
    }
   ],
   "source": [
    "# Split into train, remain, with stratify to maintain class proportion for each set\n",
    "x_train, x_remain, y_train, y_remain = train_test_split(vector_array, encoded_labels, stratify = encoded_labels, \n",
    "                                                    train_size=0.7, random_state=88)\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"x_remain shape: \", x_remain.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_remain shape: \", y_remain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_val shape:  (34808, 3000)\n",
      "x_test shape:  (34809, 3000)\n",
      "y_val shape:  (34808,)\n",
      "y_test shape:  (34809,)\n"
     ]
    }
   ],
   "source": [
    "# Split into val, test\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_remain, y_remain, stratify = y_remain, \n",
    "                                                    train_size=0.5, random_state=88)\n",
    "print(\"x_val shape: \", x_val.shape)\n",
    "print(\"x_test shape: \", x_test.shape)\n",
    "print(\"y_val shape: \", y_val.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
